{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "rootpath = '/media/share/data/kaggle/ieee-camera/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_generater(rootpath, dataset):\n",
    "    # find all the camera\n",
    "    subdir = os.path.join(rootpath, dataset)\n",
    "    n_class = os.listdir(subdir)\n",
    "    df_temp = []\n",
    "\n",
    "    for i in n_class:\n",
    "        for fname in os.listdir(os.path.join(subdir, i)):\n",
    "            df_temp.append((i, fname))\n",
    "\n",
    "    df = pd.DataFrame(df_temp, columns=['class', 'fname'])\n",
    "    print('class:', n_class)\n",
    "    print('number of file:', df.shape[0])\n",
    "    \n",
    "    return df, n_class\n",
    "\n",
    "\n",
    "def preprocess(rootpath, dataset):\n",
    "    # read image file and check channels    \n",
    "    df, _ = df_generater(rootpath, dataset)\n",
    "    subpath = os.path.join(rootpath, dataset)\n",
    "\n",
    "    img_para = []\n",
    "    for idx in range(len(df)):\n",
    "        img = plt.imread(os.path.join(subpath, df['class'][idx]) + '/' + df['fname'][idx])\n",
    "        if img.shape[0] > img.shape[1]:\n",
    "            img = img.transpose(1, 0, 2)\n",
    "        # image size as a feature\n",
    "        img_para.append((img.shape[1], img.shape[0]/img.shape[1]))\n",
    "    \n",
    "    img_para = pd.DataFrame(img_para, columns=['size', 'ratio'])\n",
    "    df = pd.concat([df, img_para], 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def train_val_split(df, train_size=0.8):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    n_class = ['Motorola-X', \n",
    "               'HTC-1-M7', \n",
    "               'iPhone-4s', \n",
    "               'Samsung-Galaxy-Note3', \n",
    "               'Motorola-Nexus-6', \n",
    "               'LG-Nexus-5x', \n",
    "               'Samsung-Galaxy-S4', \n",
    "               'Motorola-Droid-Maxx', \n",
    "               'iPhone-6', \n",
    "               'Sony-NEX-7']\n",
    "    le = LabelEncoder().fit(n_class)\n",
    "    \n",
    "    tidx = np.arange(len(df))\n",
    "    np.random.shuffle(tidx)\n",
    "    tidx = pd.DataFrame(tidx, columns=['idx'])\n",
    "    df_0 = pd.concat([df, tidx], 1)\n",
    "    df_0 = df_0.sort_values(by=['idx'])\n",
    "    \n",
    "    trains = int(train_size * len(df))\n",
    "    X_train = df['image'][:trains] / 255.\n",
    "    X_val = df['image'][trains:] / 255.\n",
    "    y_train = le.transform(df['class'][:trains])\n",
    "    y_val = le.transform(df['class'][trains:])\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "\n",
    "def image_crop(rootpath, dataset='train', crop_size=256):\n",
    "    from skimage.util import crop\n",
    "    df, _ = df_generater(rootpath, dataset)\n",
    "    subpath = os.path.join(rootpath, dataset)\n",
    "    \n",
    "    img_file = []\n",
    "    label = []\n",
    "    for idx in range(len(df)):\n",
    "        img = plt.imread(os.path.join(subpath, df['class'][idx]) + '/' + df['fname'][idx])\n",
    "        if img.shape[0] > img.shape[1]:\n",
    "            img = img.transpose(1, 0, 2)\n",
    "\n",
    "        h1, w1, _ = img.shape\n",
    "        h2 = int(h1/int(h1/crop_size))\n",
    "        w2 = int(w1/int(w1/crop_size))\n",
    "        \n",
    "        for i in range(int(h1/crop_size)):\n",
    "            hr = np.random.randint(i*h2, (i+1)*h2-crop_size)\n",
    "            for j in range(int(w1/crop_size)):\n",
    "                wr = np.random.randint(j*w2, (j+1)*w2-crop_size)\n",
    "                img_file.append(img[hr:hr+crop_size, wr:wr+crop_size] / 255.)\n",
    "                label.append(df['class'][idx])\n",
    "\n",
    "    img_array = pd.DataFrame(img_file, columns=['class', 'image'])\n",
    "    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: ['Motorola-X', 'HTC-1-M7', 'iPhone-4s', 'Samsung-Galaxy-Note3', 'Motorola-Nexus-6', 'LG-Nexus-5x', 'Samsung-Galaxy-S4', 'Motorola-Droid-Maxx', 'iPhone-6', 'Sony-NEX-7']\n",
      "number of file: 2750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "df_train, _ = df_generater(rootpath, dataset='train')\n",
    "n_fold = 5\n",
    "skf = StratifiedKFold(n_fold, shuffle=True, random_state=np.random)\n",
    "for train_idx, val_idx in skf.split(df_train['fname'], df_train['class']):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "base_model = inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "prediction = Dense(9, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = image_crop(rootpath, 'train', crop_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(featurewise_std_normalization=True,\n",
    "                               samplewise_std_normalization=True, \n",
    "                               rotation_range=45, \n",
    "                               horizontal_flip=True, \n",
    "                               vertical_flip=True)\n",
    "\n",
    "train_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('ieeev2-{epoch:02d}-{val_loss:.5f}.hdf5',\n",
    "                                   monitor='val_loss', save_best_only=True, save_weights_only=True, )\n",
    "\n",
    "model_earlystop = EarlyStopping(patience=64, monitor='val_loss')\n",
    "adlr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=16, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=1e-6)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_history = model.fit_generator(train_gen.flow(X_train, y_train, batch_size), \n",
    "                                    epochs=2**1, steps_per_epoch=(len(X_train)//batch_size), \n",
    "                                    validation_data=train_gen.flow(X_val, y_val, batch_size), \n",
    "                                    validation_steps=(len(X_val)//batch_size),\n",
    "                                    verbose=0, callbacks=[model_checkpoint, adlr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
