{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE Camera Model Identification\n",
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 GPUs, will attempt to use all of them.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.data import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.exposure import adjust_gamma\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import urllib\n",
    "from scipy import ndimage\n",
    "\n",
    "from random import sample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D, Activation, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.optimizers import Adam, SGD, Adadelta, Nadam\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import Sequence\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.applications.densenet import DenseNet201\n",
    "import math\n",
    "\n",
    "## MultiGPU Code\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))\n",
    "import keras.utils.training_utils\n",
    "from keras.utils import multi_gpu_model\n",
    "gdev = keras.utils.training_utils._get_available_devices()\n",
    "gdev_count = 0\n",
    "for i, n in enumerate(gdev):\n",
    "    if 'device:GPU' in n:\n",
    "        gdev_count+=1\n",
    "if gdev_count > 0:\n",
    "    print('Found {} GPUs, will attempt to use all of them.'.format(gdev_count))\n",
    "else:\n",
    "    gdev_count=1\n",
    "    print('Did not find any GPUs, this will be SLOW!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths and other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var kernel = IPython.notebook.kernel;\n",
       "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
       "var command = \"session_name = \" + \"'\"+thename+\"'\";\n",
       "kernel.execute(command);"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"session_name = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/media/share/data/kaggle/ieee-camera/'\n",
    "train_path = os.path.join(input_path,'train')\n",
    "test_path = os.path.join(input_path,'test')\n",
    "flickr_path = os.path.join(input_path,'flickr_images')\n",
    "img_rows = 512\n",
    "img_cols = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2750, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>(MotoX)1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>(MotoX)10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>(MotoX)100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>(MotoX)101.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>(MotoX)102.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       camera           fname\n",
       "0  Motorola-X    (MotoX)1.jpg\n",
       "1  Motorola-X   (MotoX)10.jpg\n",
       "2  Motorola-X  (MotoX)100.jpg\n",
       "3  Motorola-X  (MotoX)101.jpg\n",
       "4  Motorola-X  (MotoX)102.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cameras = os.listdir(train_path)\n",
    "\n",
    "train_images = []\n",
    "for camera in cameras:\n",
    "    for fname in sorted(os.listdir(os.path.join(train_path,camera))):\n",
    "        train_images.append((camera, fname))\n",
    "\n",
    "train = pd.DataFrame(train_images, columns=['camera', 'fname'])\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2640, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0002a04_manip.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_001e31c_unalt.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00275cf_manip.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0034113_unalt.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00344b7_unalt.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fname\n",
       "0  img_0002a04_manip.tif\n",
       "1  img_001e31c_unalt.tif\n",
       "2  img_00275cf_manip.tif\n",
       "3  img_0034113_unalt.tif\n",
       "4  img_00344b7_unalt.tif"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = []\n",
    "for fname in sorted(os.listdir(test_path)):\n",
    "    test_images.append(fname)\n",
    "\n",
    "test = pd.DataFrame(test_images, columns=['fname'])\n",
    "print(test.shape)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11603, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>23936849344_51b33456f3_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>23954069334_58f4e3a6d7_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>23956920324_19d0cdee07_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>23957852063_2194f748d2_o.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>23962520803_5c85ac0b75_o.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       camera                         fname\n",
       "0  Motorola-X  23936849344_51b33456f3_o.jpg\n",
       "1  Motorola-X  23954069334_58f4e3a6d7_o.jpg\n",
       "2  Motorola-X  23956920324_19d0cdee07_o.jpg\n",
       "3  Motorola-X  23957852063_2194f748d2_o.jpg\n",
       "4  Motorola-X  23962520803_5c85ac0b75_o.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr_images = []\n",
    "for camera in cameras:\n",
    "    for fname in sorted(os.listdir(os.path.join(flickr_path,camera))):\n",
    "        if fname.endswith('jpg') or fname.endswith('png'):\n",
    "            flickr_images.append((camera, fname))\n",
    "\n",
    "flickr = pd.DataFrame(flickr_images, columns=['camera', 'fname'])\n",
    "print(flickr.shape)\n",
    "flickr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71535142 1.45219024 0.90719312 0.79910468 0.96691667 1.73179104\n",
      " 0.89391371 1.65757143 0.90366044 0.89322556]\n"
     ]
    }
   ],
   "source": [
    "# Compute a class_weight\n",
    "# orig_class_weights = class_weight.compute_class_weight('balanced', np.asarray(cameras), train['camera'])\n",
    "# print(orig_class_weights)\n",
    "flickr_class_weights = class_weight.compute_class_weight('balanced', np.asarray(cameras), flickr['camera'])\n",
    "print(flickr_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0,0,0,1],[0,1,0,0]]).argsort(axis=1)[:,::-1][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to build image set using the training data set\n",
    "This way we can apply multiprocessing to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpf = np.array([[-1,2,-2,2,-1],\n",
    "               [2,-6,8,-6,2],\n",
    "               [-2,8,-12,8,-2],\n",
    "               [2,-6,8,-6,2],\n",
    "               [-1,2,-2,2,-1]], dtype=np.float32)\n",
    "hpf = (1/12)*hpf\n",
    "hpf = np.dstack([np.zeros(hpf.shape),hpf,np.zeros(hpf.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_image_set(j):\n",
    "    # Read image\n",
    "    img = np.array(Image.open(os.path.join(os.path.join(train_path,train['camera'].iloc[j]),train['fname'].iloc[j])), dtype=np.uint8)\n",
    "    \n",
    "    # Add some augmentation\n",
    "    #JPEG compression with quality factor = 70\n",
    "    #JPEG compression with quality factor = 90\n",
    "    #resizing (via bicubic interpolation) by a factor of 0.5\n",
    "    #resizing (via bicubic interpolation) by a factor of 0.8\n",
    "    #resizing (via bicubic interpolation) by a factor of 1.5\n",
    "    #resizing (via bicubic interpolation) by a factor of 2.0\n",
    "    #gamma correction using gamma = 0.8\n",
    "    #gamma correction using gamma = 1.2\n",
    "    if np.random.randint(2) < 1:\n",
    "        tmp_stream = BytesIO()\n",
    "        tmp_img = Image.fromarray(img)\n",
    "        tmp_img.save(tmp_stream, format='jpeg', quality=int(np.random.choice([70,90])))\n",
    "        tmp_stream.seek(0)\n",
    "        img = np.array(Image.open(tmp_stream))\n",
    "        img = np.array(resize(img,np.round(np.multiply(img.shape[:2],np.random.choice([0.5,0.8,1.5,2.0]))),\n",
    "                              mode='reflect', preserve_range=True, order=3), dtype=np.uint8)\n",
    "        img = adjust_gamma(img, gamma=np.random.choice([0.8,1.2]))\n",
    "    \n",
    "    # Get dimensions\n",
    "    dim_x = img.shape[0]\n",
    "    dim_y = img.shape[1]\n",
    "    \n",
    "    # Set temp img\n",
    "    tmp_img = ndimage.convolve(img.astype(np.float32), hpf, mode='mirror')\n",
    "    tmp_img = img.astype(np.float32) - tmp_img\n",
    "    tmp_img = tmp_img.astype(np.float16)\n",
    "    \n",
    "    # Find out if image needs padding using %\n",
    "#     if (dim_x % img_rows) != 0:\n",
    "#         tmp_img = np.pad(tmp_img, ([0,img_rows-(dim_x % img_rows)],[0,0],[0,0]), 'reflect')\n",
    "#     if (dim_y % img_cols) != 0:\n",
    "#         tmp_img = np.pad(tmp_img, ([0,0],[0,img_cols-(dim_y % img_cols)],[0,0]), 'reflect')\n",
    "    \n",
    "    # Next, extract a random square\n",
    "    cropped_imgs = []\n",
    "    labels = []\n",
    "    for i in range(25):\n",
    "        m = np.random.randint(math.floor(dim_x / img_rows))\n",
    "        n = np.random.randint(math.floor(dim_y / img_cols))\n",
    "        xx_img = tmp_img[m*img_rows:(m+1)*img_rows,n*img_cols:(n+1)*img_cols,:]\n",
    "        lab = np.zeros(len(cameras))\n",
    "        lab[cameras.index(train['camera'].iloc[j])] = 1\n",
    "        cropped_imgs += [xx_img]\n",
    "        labels += [lab]\n",
    "    \n",
    "    return cropped_imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_image_set(j):\n",
    "    # Read image\n",
    "    img = np.array(Image.open(os.path.join(test_path,test['fname'].iloc[j])))\n",
    "        \n",
    "    # Get dimensions\n",
    "    dim_x = img.shape[0]\n",
    "    dim_y = img.shape[1]\n",
    "    \n",
    "    # Set temp img\n",
    "    tmp_img = ndimage.convolve(img.astype(np.float32), hpf, mode='mirror')\n",
    "    tmp_img = img.astype(np.float32) - tmp_img\n",
    "    \n",
    "    # Find out if image needs padding using %\n",
    "    if (dim_x % img_rows) != 0:\n",
    "        tmp_img = np.pad(tmp_img, ([0,img_rows-(dim_x % img_rows)],[0,0],[0,0]), 'reflect')\n",
    "    if (dim_y % img_cols) != 0:\n",
    "        tmp_img = np.pad(tmp_img, ([0,0],[0,img_cols-(dim_y % img_cols)],[0,0]), 'reflect')\n",
    "        \n",
    "    tmp_img = tmp_img.astype(np.float16)\n",
    "    \n",
    "    # Next, cut up the little squares\n",
    "#     cropped_imgs = []\n",
    "#     for m in range(math.ceil(dim_x / img_rows)):\n",
    "#         for n in range(math.ceil(dim_y / img_cols)):\n",
    "#             xx_img = tmp_img[m*img_rows:(m+1)*img_rows,n*img_cols:(n+1)*img_cols,:]\n",
    "#             cropped_imgs += [xx_img]\n",
    "    \n",
    "    return tmp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_flickr_image_set(j):\n",
    "    # Read image\n",
    "    img = np.array(Image.open(os.path.join(os.path.join(flickr_path,flickr['camera'].iloc[j]),flickr['fname'].iloc[j])), dtype=np.uint8)\n",
    "    if len(img.shape)<3:\n",
    "#         print('Error loading file, possible grayscale image',flickr['camera'].iloc[j], flickr['fname'].iloc[j])\n",
    "        return 0,0\n",
    "    if img.shape[2] != 3:\n",
    "#         print('Error loading file, incorrect number of channels',flickr['camera'].iloc[j], flickr['fname'].iloc[j])\n",
    "        return 0,0\n",
    "    \n",
    "    # Get dimensions\n",
    "    dim_x = img.shape[0]\n",
    "    dim_y = img.shape[1]\n",
    "    \n",
    "    # Set temp img\n",
    "    tmp_img = ndimage.convolve(img.astype(np.float32), hpf, mode='mirror')\n",
    "    tmp_img = img.astype(np.float32) - tmp_img\n",
    "    tmp_img = tmp_img.astype(np.float16)\n",
    "    \n",
    "    try:\n",
    "        cropped_imgs = []\n",
    "        labels = []\n",
    "        # get 5 images\n",
    "        for i in range(8):\n",
    "            m = np.random.randint(math.floor(dim_x / img_rows))\n",
    "            n = np.random.randint(math.floor(dim_y / img_cols))\n",
    "            xx_img = tmp_img[m*img_rows:(m+1)*img_rows,n*img_cols:(n+1)*img_cols,:]\n",
    "            lab = np.zeros(len(cameras))\n",
    "            lab[cameras.index(flickr['camera'].iloc[j])] = 1\n",
    "            cropped_imgs += [xx_img]\n",
    "            labels += [lab]\n",
    "        return cropped_imgs, labels\n",
    "    except:\n",
    "#         print('Error loading file',flickr['camera'].iloc[j], flickr['fname'].iloc[j])\n",
    "        return 0,0\n",
    "    #xx_img = xx_img - ndimage.convolve(xx_img, hpf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold Train split (0.9 Train, 0.1 Validation)\n",
    "By splitting here, we can ensure that the cropped images aren't in both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_folds, shuffle=True, random_state=np.random)\n",
    "for train_index, test_index in skf.split(np.arange(len(train)), train['camera']):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocess train/val/test sets by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Flickr Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 7. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Importing Flickr Images\n",
      "Importing Training Set\n",
      "Done Importing Training Set\n",
      "Importing Validation Set\n",
      "Done Importing Validation Set\n",
      "Importing Test Set\n",
      "Done Importing Test Set\n"
     ]
    }
   ],
   "source": [
    "with Pool(cpu_count()) as pool:\n",
    "    print('Importing Flickr Images')\n",
    "    flickr_imgs, flickr_labels = zip(*pool.map(build_flickr_image_set, range(len(flickr))))\n",
    "    flickr_imgs = [x for x in flickr_imgs if not isinstance(x, int)]\n",
    "    flickr_labels = [x for x in flickr_labels if not isinstance(x, int)]\n",
    "    flickr_imgs = list(itertools.chain(*flickr_imgs))\n",
    "    flickr_labels = list(itertools.chain(*flickr_labels))\n",
    "    print('Done Importing Flickr Images')\n",
    "    print('Importing Training Set')\n",
    "    train_imgs, train_labels = zip(*pool.map(build_train_image_set, train_index))\n",
    "    train_imgs = list(itertools.chain(*train_imgs))\n",
    "    train_labels = list(itertools.chain(*train_labels))\n",
    "    print('Done Importing Training Set')\n",
    "    print('Importing Validation Set')\n",
    "    val_imgs, val_labels = zip(*pool.map(build_train_image_set, test_index))\n",
    "    val_imgs = list(itertools.chain(*val_imgs))\n",
    "    val_labels = list(itertools.chain(*val_labels))\n",
    "    print('Done Importing Validation Set')\n",
    "    print('Importing Test Set')\n",
    "    test_imgs = pool.map(build_test_image_set, range(len(test)))\n",
    "#     test_imgs = list(itertools.chain(*test_imgs))\n",
    "    print('Done Importing Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SEInceptionResnetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 256, 256, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 256, 256, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 258, 258, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 128, 128, 64) 0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 128, 128, 64) 256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 128, 128, 64) 0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 128 8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 128 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 128, 128, 96) 0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 128, 128, 96) 384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 128, 128, 96) 0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 128 12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 128 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 128, 128, 128 0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 128, 128, 128 512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 128, 128, 128 0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 128 16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 128 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 128, 128, 160 0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 128, 128, 160 640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 128, 128, 160 0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 128, 128, 128 20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 128, 128, 128 0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 128, 128, 192 0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 128, 128, 192 768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 128, 128, 192 0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 128, 128, 128 24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 128, 128, 128 0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 128, 128, 224 0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 128, 128, 224 896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 128, 128, 224 0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 128, 128, 128 28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 128, 128, 128 0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 128, 128, 256 0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 128, 128, 256 1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 128, 128, 256 0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 128, 128, 128 32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 64, 64, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 64, 64, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 64, 64, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 64, 64, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 64, 64, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 64, 64, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 64, 64, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 64, 64, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 64, 64, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 64, 64, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 64, 64, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 64, 64, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 64, 64, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 64, 64, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 64, 64, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 64, 64, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 64, 64, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 64, 64, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 64, 64, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 64, 64, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 64, 64, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 64, 64, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 64, 64, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 64, 64, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 64, 64, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 64, 64, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 64, 64, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 64, 64, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 64, 64, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 64, 64, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 64, 64, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 64, 64, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 64, 64, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 64, 64, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 64, 64, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 64, 64, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 64, 64, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 64, 64, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 64, 64, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 64, 64, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 64, 64, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 64, 64, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 64, 64, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 64, 64, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 64, 64, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 64, 64, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 64, 64, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 64, 64, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 64, 64, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 64, 64, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 64, 64, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 32, 32, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 32, 32, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 32, 32, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 32, 32, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 32, 32, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 32, 32, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 32, 32, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 32, 32, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 32, 32, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 32, 32, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 32, 32, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 32, 32, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 32, 32, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 32, 32, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 32, 32, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 32, 32, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 32, 32, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 32, 32, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 32, 32, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 32, 32, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 32, 32, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 32, 32, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 32, 32, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 32, 32, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 32, 32, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 32, 32, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 32, 32, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 32, 32, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 32, 32, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 32, 32, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 32, 32, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 32, 32, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 32, 32, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 32, 32, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 32, 32, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 32, 32, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 32, 32, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 32, 32, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 32, 32, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 32, 32, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 32, 32, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 32, 32, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 32, 32, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 32, 32, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 32, 32, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 32, 32, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 32, 32, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 32, 32, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 32, 32, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 32, 32, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 32, 32, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 32, 32, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 32, 32, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 32, 32, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 32, 32, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 32, 32, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 32, 32, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 32, 32, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 32, 32, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 32, 32, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 32, 32, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 32, 32, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 32, 32, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 32, 32, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 32, 32, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 32, 32, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 32, 32, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 32, 32, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 32, 32, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 32, 32, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 32, 32, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 32, 32, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 32, 32, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 32, 32, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 32, 32, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 32, 32, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 32, 32, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 32, 32, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 32, 32, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 32, 32, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 32, 32, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 32, 32, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 32, 32, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 32, 32, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 32, 32, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 32, 32, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 32, 32, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 32, 32, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 32, 32, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 32, 32, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 32, 32, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 32, 32, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 32, 32, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 32, 32, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 32, 32, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 32, 32, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 32, 32, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 32, 32, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 32, 32, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 32, 32, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 32, 32, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 32, 32, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 32, 32, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 32, 32, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 32, 32, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 32, 32, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 32, 32, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 32, 32, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 32, 32, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 32, 32, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 32, 32, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 32, 32, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 32, 32, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 32, 32, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 32, 32, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 32, 32, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 32, 32, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 32, 32, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 32, 32, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 32, 32, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 32, 32, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 32, 32, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 32, 32, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_bn (BatchNormal (None, 32, 32, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_relu (Activatio (None, 32, 32, 1280) 0           conv4_block33_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 32, 32, 128)  163840      conv4_block33_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_concat (Concatena (None, 32, 32, 1312) 0           conv4_block32_concat[0][0]       \n",
      "                                                                 conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_bn (BatchNormal (None, 32, 32, 1312) 5248        conv4_block33_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_relu (Activatio (None, 32, 32, 1312) 0           conv4_block34_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 32, 32, 128)  167936      conv4_block34_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_concat (Concatena (None, 32, 32, 1344) 0           conv4_block33_concat[0][0]       \n",
      "                                                                 conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_bn (BatchNormal (None, 32, 32, 1344) 5376        conv4_block34_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_relu (Activatio (None, 32, 32, 1344) 0           conv4_block35_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 32, 32, 128)  172032      conv4_block35_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_concat (Concatena (None, 32, 32, 1376) 0           conv4_block34_concat[0][0]       \n",
      "                                                                 conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_bn (BatchNormal (None, 32, 32, 1376) 5504        conv4_block35_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_relu (Activatio (None, 32, 32, 1376) 0           conv4_block36_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 32, 32, 128)  176128      conv4_block36_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_concat (Concatena (None, 32, 32, 1408) 0           conv4_block35_concat[0][0]       \n",
      "                                                                 conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_bn (BatchNormal (None, 32, 32, 1408) 5632        conv4_block36_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_relu (Activatio (None, 32, 32, 1408) 0           conv4_block37_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_conv (Conv2D)   (None, 32, 32, 128)  180224      conv4_block37_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block37_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block37_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block37_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_concat (Concatena (None, 32, 32, 1440) 0           conv4_block36_concat[0][0]       \n",
      "                                                                 conv4_block37_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_bn (BatchNormal (None, 32, 32, 1440) 5760        conv4_block37_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_relu (Activatio (None, 32, 32, 1440) 0           conv4_block38_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_conv (Conv2D)   (None, 32, 32, 128)  184320      conv4_block38_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block38_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block38_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block38_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_concat (Concatena (None, 32, 32, 1472) 0           conv4_block37_concat[0][0]       \n",
      "                                                                 conv4_block38_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_bn (BatchNormal (None, 32, 32, 1472) 5888        conv4_block38_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_relu (Activatio (None, 32, 32, 1472) 0           conv4_block39_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_conv (Conv2D)   (None, 32, 32, 128)  188416      conv4_block39_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block39_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block39_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block39_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_concat (Concatena (None, 32, 32, 1504) 0           conv4_block38_concat[0][0]       \n",
      "                                                                 conv4_block39_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_bn (BatchNormal (None, 32, 32, 1504) 6016        conv4_block39_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_relu (Activatio (None, 32, 32, 1504) 0           conv4_block40_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_conv (Conv2D)   (None, 32, 32, 128)  192512      conv4_block40_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block40_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block40_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block40_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_concat (Concatena (None, 32, 32, 1536) 0           conv4_block39_concat[0][0]       \n",
      "                                                                 conv4_block40_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_bn (BatchNormal (None, 32, 32, 1536) 6144        conv4_block40_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_relu (Activatio (None, 32, 32, 1536) 0           conv4_block41_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_conv (Conv2D)   (None, 32, 32, 128)  196608      conv4_block41_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block41_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block41_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block41_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_concat (Concatena (None, 32, 32, 1568) 0           conv4_block40_concat[0][0]       \n",
      "                                                                 conv4_block41_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_bn (BatchNormal (None, 32, 32, 1568) 6272        conv4_block41_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_relu (Activatio (None, 32, 32, 1568) 0           conv4_block42_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_conv (Conv2D)   (None, 32, 32, 128)  200704      conv4_block42_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block42_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block42_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block42_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_concat (Concatena (None, 32, 32, 1600) 0           conv4_block41_concat[0][0]       \n",
      "                                                                 conv4_block42_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_bn (BatchNormal (None, 32, 32, 1600) 6400        conv4_block42_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_relu (Activatio (None, 32, 32, 1600) 0           conv4_block43_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_conv (Conv2D)   (None, 32, 32, 128)  204800      conv4_block43_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block43_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block43_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block43_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_concat (Concatena (None, 32, 32, 1632) 0           conv4_block42_concat[0][0]       \n",
      "                                                                 conv4_block43_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_bn (BatchNormal (None, 32, 32, 1632) 6528        conv4_block43_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_relu (Activatio (None, 32, 32, 1632) 0           conv4_block44_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_conv (Conv2D)   (None, 32, 32, 128)  208896      conv4_block44_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block44_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block44_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block44_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_concat (Concatena (None, 32, 32, 1664) 0           conv4_block43_concat[0][0]       \n",
      "                                                                 conv4_block44_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_bn (BatchNormal (None, 32, 32, 1664) 6656        conv4_block44_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_relu (Activatio (None, 32, 32, 1664) 0           conv4_block45_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_conv (Conv2D)   (None, 32, 32, 128)  212992      conv4_block45_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block45_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block45_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block45_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_concat (Concatena (None, 32, 32, 1696) 0           conv4_block44_concat[0][0]       \n",
      "                                                                 conv4_block45_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_bn (BatchNormal (None, 32, 32, 1696) 6784        conv4_block45_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_relu (Activatio (None, 32, 32, 1696) 0           conv4_block46_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_conv (Conv2D)   (None, 32, 32, 128)  217088      conv4_block46_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block46_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block46_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block46_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_concat (Concatena (None, 32, 32, 1728) 0           conv4_block45_concat[0][0]       \n",
      "                                                                 conv4_block46_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_bn (BatchNormal (None, 32, 32, 1728) 6912        conv4_block46_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_relu (Activatio (None, 32, 32, 1728) 0           conv4_block47_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_conv (Conv2D)   (None, 32, 32, 128)  221184      conv4_block47_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block47_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block47_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block47_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_concat (Concatena (None, 32, 32, 1760) 0           conv4_block46_concat[0][0]       \n",
      "                                                                 conv4_block47_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_bn (BatchNormal (None, 32, 32, 1760) 7040        conv4_block47_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_relu (Activatio (None, 32, 32, 1760) 0           conv4_block48_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_conv (Conv2D)   (None, 32, 32, 128)  225280      conv4_block48_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block48_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block48_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block48_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_concat (Concatena (None, 32, 32, 1792) 0           conv4_block47_concat[0][0]       \n",
      "                                                                 conv4_block48_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 32, 32, 1792) 7168        conv4_block48_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 32, 32, 1792) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 32, 32, 896)  1605632     pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 16, 16, 896)  0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 16, 16, 896)  3584        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 16, 16, 896)  0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 128)  114688      conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 16, 16, 128)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 16, 16, 928)  0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 16, 16, 928)  3712        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 16, 16, 928)  0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 128)  118784      conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 16, 16, 128)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 16, 16, 960)  0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 16, 16, 960)  3840        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 16, 16, 960)  0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 128)  122880      conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 16, 16, 128)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 16, 16, 992)  0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 16, 16, 992)  3968        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 16, 16, 992)  0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 16, 16, 128)  126976      conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 16, 16, 128)  0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 16, 16, 1024) 0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 16, 16, 1024) 0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 16, 16, 128)  131072      conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 16, 16, 128)  0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 16, 16, 1056) 0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 16, 16, 1056) 4224        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 16, 16, 1056) 0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 16, 16, 128)  135168      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 16, 16, 128)  0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 16, 16, 1088) 0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 16, 16, 1088) 4352        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 16, 16, 1088) 0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 16, 16, 128)  139264      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 16, 16, 128)  0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 16, 16, 1120) 0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 16, 16, 1120) 4480        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 16, 16, 1120) 0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 16, 16, 128)  143360      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 16, 16, 128)  0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 16, 16, 1152) 0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 16, 16, 1152) 4608        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 16, 16, 1152) 0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 16, 16, 128)  147456      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 16, 16, 128)  0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 16, 16, 1184) 0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 16, 16, 1184) 4736        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 16, 16, 1184) 0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 16, 16, 128)  151552      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 16, 16, 1216) 0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 16, 16, 1216) 4864        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 16, 16, 1216) 0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 16, 16, 128)  155648      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 16, 16, 1248) 0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 16, 16, 1248) 4992        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 16, 16, 1248) 0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 16, 16, 128)  159744      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 16, 16, 1280) 0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 16, 16, 1280) 5120        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 16, 16, 1280) 0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 16, 16, 128)  163840      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 16, 16, 1312) 0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 16, 16, 1312) 5248        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 16, 16, 1312) 0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 16, 16, 128)  167936      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 16, 16, 1344) 0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 16, 16, 1344) 5376        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 16, 16, 1344) 0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 16, 16, 128)  172032      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 16, 16, 1376) 0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 16, 16, 1376) 5504        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 16, 16, 1376) 0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 16, 16, 128)  176128      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 16, 16, 1408) 0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 16, 16, 1408) 5632        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 16, 16, 1408) 0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 16, 16, 128)  180224      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 16, 16, 1440) 0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 16, 16, 1440) 5760        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 16, 16, 1440) 0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 16, 16, 128)  184320      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 16, 16, 1472) 0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 16, 16, 1472) 5888        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 16, 16, 1472) 0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 16, 16, 128)  188416      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 16, 16, 1504) 0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 16, 16, 1504) 6016        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 16, 16, 1504) 0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 16, 16, 128)  192512      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 16, 16, 1536) 0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 16, 16, 1536) 6144        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 16, 16, 1536) 0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 16, 16, 128)  196608      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 16, 16, 1568) 0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 16, 16, 1568) 6272        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 16, 16, 1568) 0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 16, 16, 128)  200704      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 16, 16, 1600) 0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 16, 16, 1600) 6400        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 16, 16, 1600) 0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 16, 16, 128)  204800      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 16, 16, 1632) 0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 16, 16, 1632) 6528        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 16, 16, 1632) 0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 16, 16, 128)  208896      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 16, 16, 1664) 0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 16, 16, 1664) 6656        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 16, 16, 1664) 0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 16, 16, 128)  212992      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 16, 16, 1696) 0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 16, 16, 1696) 6784        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 16, 16, 1696) 0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 16, 16, 128)  217088      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 16, 16, 1728) 0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 16, 16, 1728) 6912        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 16, 16, 1728) 0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 16, 16, 128)  221184      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 16, 16, 1760) 0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 16, 16, 1760) 7040        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 16, 16, 1760) 0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 16, 16, 128)  225280      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 16, 16, 1792) 0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 16, 16, 1792) 7168        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 16, 16, 1792) 0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 16, 16, 128)  229376      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 16, 16, 1824) 0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 16, 16, 1824) 7296        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 16, 16, 1824) 0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 16, 16, 128)  233472      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 16, 16, 1856) 0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 16, 16, 1856) 7424        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 16, 16, 1856) 0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 16, 16, 128)  237568      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 16, 16, 1888) 0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 16, 16, 1888) 7552        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 16, 16, 1888) 0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 16, 16, 128)  241664      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 16, 16, 1920) 0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 16, 16, 1920) 7680        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1920)         0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           19210       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 18,341,194\n",
      "Trainable params: 18,112,138\n",
      "Non-trainable params: 229,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 10)           18341194    lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Concatenate)           (None, 10)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "                                                                 model_1[5][0]                    \n",
      "                                                                 model_1[6][0]                    \n",
      "                                                                 model_1[7][0]                    \n",
      "                                                                 model_1[8][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,341,194\n",
      "Trainable params: 18,112,138\n",
      "Non-trainable params: 229,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "seres_model = DenseNet201(include_top=False, weights='imagenet', pooling=None, input_shape=(img_rows,img_cols,3))\n",
    "# x = Flatten()(seres_model.output)\n",
    "# x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(seres_model.output)\n",
    "x = Dense(len(cameras), activation='softmax')(x)\n",
    "smodel = Model(seres_model.input, x)\n",
    "\n",
    "# MultiGPU Code\n",
    "smodel.summary()\n",
    "if gdev_count > 1:\n",
    "    model = multi_gpu_model(smodel, gdev_count)\n",
    "    model.summary()\n",
    "else:\n",
    "    model = smodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            np.arange(len(cameras)),\n",
    "                                            np.asarray(flickr_labels+train_labels).argsort(axis=1)[:,::-1][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x, y, b):\n",
    "    while True:\n",
    "        x_out, y_out = zip(*sample(list(zip(x, y)), b))\n",
    "        yield np.asarray(x_out), np.asarray(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4096\n",
      " - 205s - loss: 2.2108 - acc: 0.2195 - val_loss: 9.0120 - val_acc: 0.2041\n",
      "Epoch 2/4096\n",
      " - 113s - loss: 1.9228 - acc: 0.3252 - val_loss: 3.7991 - val_acc: 0.1885\n",
      "Epoch 3/4096\n",
      " - 114s - loss: 1.7108 - acc: 0.4109 - val_loss: 2.8209 - val_acc: 0.3057\n",
      "Epoch 4/4096\n",
      " - 112s - loss: 1.5379 - acc: 0.4797 - val_loss: 4.9945 - val_acc: 0.2256\n",
      "Epoch 5/4096\n",
      " - 115s - loss: 1.4690 - acc: 0.5020 - val_loss: 1.9225 - val_acc: 0.4307\n",
      "Epoch 6/4096\n",
      " - 111s - loss: 1.3368 - acc: 0.5554 - val_loss: 3.8479 - val_acc: 0.2686\n",
      "Epoch 7/4096\n",
      " - 113s - loss: 1.2588 - acc: 0.5806 - val_loss: 2.2740 - val_acc: 0.4541\n",
      "Epoch 8/4096\n",
      " - 110s - loss: 1.1667 - acc: 0.6018 - val_loss: 3.6439 - val_acc: 0.2793\n",
      "Epoch 9/4096\n",
      " - 115s - loss: 1.1127 - acc: 0.6240 - val_loss: 1.6943 - val_acc: 0.5352\n",
      "Epoch 10/4096\n",
      " - 111s - loss: 1.0736 - acc: 0.6399 - val_loss: 2.7661 - val_acc: 0.2891\n",
      "Epoch 11/4096\n",
      " - 110s - loss: 1.0584 - acc: 0.6414 - val_loss: 2.1840 - val_acc: 0.4580\n",
      "Epoch 12/4096\n",
      " - 110s - loss: 0.9943 - acc: 0.6619 - val_loss: 2.4955 - val_acc: 0.3945\n",
      "Epoch 13/4096\n",
      " - 112s - loss: 0.9879 - acc: 0.6660 - val_loss: 2.1399 - val_acc: 0.4609\n",
      "Epoch 14/4096\n",
      " - 113s - loss: 0.9751 - acc: 0.6604 - val_loss: 1.4248 - val_acc: 0.5107\n",
      "Epoch 15/4096\n",
      " - 113s - loss: 0.9162 - acc: 0.6873 - val_loss: 1.6604 - val_acc: 0.5508\n",
      "Epoch 16/4096\n",
      " - 110s - loss: 0.9039 - acc: 0.6921 - val_loss: 1.9428 - val_acc: 0.5254\n",
      "Epoch 17/4096\n",
      " - 113s - loss: 0.8618 - acc: 0.7053 - val_loss: 1.4502 - val_acc: 0.5557\n",
      "Epoch 18/4096\n",
      " - 115s - loss: 0.8069 - acc: 0.7280 - val_loss: 0.9675 - val_acc: 0.6846\n",
      "Epoch 19/4096\n",
      " - 111s - loss: 0.8436 - acc: 0.7170 - val_loss: 1.9437 - val_acc: 0.5166\n",
      "Epoch 20/4096\n",
      " - 111s - loss: 0.8314 - acc: 0.7207 - val_loss: 1.6964 - val_acc: 0.5557\n",
      "Epoch 21/4096\n",
      " - 111s - loss: 0.8080 - acc: 0.7246 - val_loss: 1.9056 - val_acc: 0.4902\n",
      "Epoch 22/4096\n",
      " - 111s - loss: 0.8004 - acc: 0.7341 - val_loss: 1.9131 - val_acc: 0.4893\n",
      "Epoch 23/4096\n",
      " - 112s - loss: 0.7842 - acc: 0.7415 - val_loss: 1.5283 - val_acc: 0.5557\n",
      "Epoch 24/4096\n",
      " - 111s - loss: 0.7585 - acc: 0.7400 - val_loss: 3.4067 - val_acc: 0.3691\n",
      "Epoch 25/4096\n",
      " - 110s - loss: 0.7165 - acc: 0.7590 - val_loss: 1.9330 - val_acc: 0.6113\n",
      "Epoch 26/4096\n",
      " - 110s - loss: 0.7651 - acc: 0.7378 - val_loss: 1.4667 - val_acc: 0.6064\n",
      "Epoch 27/4096\n",
      " - 110s - loss: 0.7010 - acc: 0.7561 - val_loss: 1.5033 - val_acc: 0.5908\n",
      "Epoch 28/4096\n",
      " - 110s - loss: 0.7136 - acc: 0.7502 - val_loss: 2.5979 - val_acc: 0.4492\n",
      "Epoch 29/4096\n",
      " - 110s - loss: 0.7031 - acc: 0.7610 - val_loss: 1.1433 - val_acc: 0.6611\n",
      "Epoch 30/4096\n",
      " - 114s - loss: 0.6727 - acc: 0.7661 - val_loss: 0.9104 - val_acc: 0.7188\n",
      "Epoch 31/4096\n",
      " - 111s - loss: 0.7124 - acc: 0.7598 - val_loss: 1.7541 - val_acc: 0.5498\n",
      "Epoch 32/4096\n",
      " - 115s - loss: 0.6916 - acc: 0.7598 - val_loss: 0.6505 - val_acc: 0.7881\n",
      "Epoch 33/4096\n",
      " - 112s - loss: 0.6936 - acc: 0.7632 - val_loss: 2.7629 - val_acc: 0.4590\n",
      "Epoch 34/4096\n",
      " - 110s - loss: 0.6693 - acc: 0.7644 - val_loss: 1.0745 - val_acc: 0.6572\n",
      "Epoch 35/4096\n",
      " - 110s - loss: 0.6507 - acc: 0.7739 - val_loss: 1.8411 - val_acc: 0.5498\n",
      "Epoch 36/4096\n",
      " - 111s - loss: 0.6709 - acc: 0.7732 - val_loss: 1.3413 - val_acc: 0.6436\n",
      "Epoch 37/4096\n",
      " - 111s - loss: 0.6423 - acc: 0.7776 - val_loss: 1.5588 - val_acc: 0.5645\n",
      "Epoch 38/4096\n",
      " - 110s - loss: 0.6294 - acc: 0.7803 - val_loss: 1.9429 - val_acc: 0.5498\n",
      "Epoch 39/4096\n",
      " - 110s - loss: 0.6454 - acc: 0.7798 - val_loss: 1.1797 - val_acc: 0.6055\n",
      "Epoch 40/4096\n",
      " - 111s - loss: 0.6079 - acc: 0.7932 - val_loss: 0.9747 - val_acc: 0.6885\n",
      "Epoch 41/4096\n",
      " - 111s - loss: 0.6284 - acc: 0.7778 - val_loss: 1.2953 - val_acc: 0.6113\n",
      "Epoch 42/4096\n",
      " - 110s - loss: 0.5867 - acc: 0.7930 - val_loss: 1.6748 - val_acc: 0.5557\n",
      "Epoch 43/4096\n",
      " - 111s - loss: 0.5805 - acc: 0.8015 - val_loss: 1.2509 - val_acc: 0.6602\n",
      "Epoch 44/4096\n",
      " - 110s - loss: 0.5841 - acc: 0.7939 - val_loss: 0.8186 - val_acc: 0.7295\n",
      "Epoch 45/4096\n",
      " - 110s - loss: 0.5872 - acc: 0.7908 - val_loss: 1.3092 - val_acc: 0.6416\n",
      "Epoch 46/4096\n",
      " - 110s - loss: 0.5677 - acc: 0.8120 - val_loss: 1.8029 - val_acc: 0.5879\n",
      "Epoch 47/4096\n",
      " - 111s - loss: 0.5543 - acc: 0.8145 - val_loss: 0.9769 - val_acc: 0.7568\n",
      "Epoch 48/4096\n",
      " - 110s - loss: 0.5976 - acc: 0.7917 - val_loss: 1.3542 - val_acc: 0.6201\n",
      "Epoch 49/4096\n",
      " - 110s - loss: 0.5417 - acc: 0.8071 - val_loss: 1.4426 - val_acc: 0.6328\n",
      "Epoch 50/4096\n",
      " - 111s - loss: 0.5853 - acc: 0.7886 - val_loss: 1.1339 - val_acc: 0.6670\n",
      "Epoch 51/4096\n",
      " - 110s - loss: 0.5335 - acc: 0.8159 - val_loss: 1.0016 - val_acc: 0.7461\n",
      "Epoch 52/4096\n",
      " - 111s - loss: 0.5372 - acc: 0.8145 - val_loss: 1.5826 - val_acc: 0.6406\n",
      "Epoch 53/4096\n",
      " - 111s - loss: 0.5457 - acc: 0.8074 - val_loss: 1.2755 - val_acc: 0.6104\n",
      "Epoch 54/4096\n",
      " - 111s - loss: 0.5479 - acc: 0.8152 - val_loss: 1.1448 - val_acc: 0.6787\n",
      "Epoch 55/4096\n",
      " - 110s - loss: 0.5312 - acc: 0.8000 - val_loss: 0.8246 - val_acc: 0.7529\n",
      "Epoch 56/4096\n",
      " - 110s - loss: 0.5276 - acc: 0.8162 - val_loss: 0.7888 - val_acc: 0.7480\n",
      "Epoch 57/4096\n",
      " - 110s - loss: 0.5131 - acc: 0.8167 - val_loss: 0.9558 - val_acc: 0.6855\n",
      "Epoch 58/4096\n",
      " - 111s - loss: 0.5296 - acc: 0.8125 - val_loss: 1.2410 - val_acc: 0.6963\n",
      "Epoch 59/4096\n",
      " - 110s - loss: 0.5114 - acc: 0.8210 - val_loss: 0.9698 - val_acc: 0.7080\n",
      "Epoch 60/4096\n",
      " - 110s - loss: 0.4962 - acc: 0.8237 - val_loss: 1.6022 - val_acc: 0.6064\n",
      "Epoch 61/4096\n",
      " - 110s - loss: 0.4965 - acc: 0.8208 - val_loss: 0.9876 - val_acc: 0.6650\n",
      "Epoch 62/4096\n",
      " - 110s - loss: 0.4889 - acc: 0.8296 - val_loss: 1.5414 - val_acc: 0.6270\n",
      "Epoch 63/4096\n",
      " - 110s - loss: 0.5102 - acc: 0.8142 - val_loss: 1.0710 - val_acc: 0.7070\n",
      "Epoch 64/4096\n",
      " - 111s - loss: 0.5216 - acc: 0.8193 - val_loss: 1.4479 - val_acc: 0.6436\n",
      "Epoch 65/4096\n",
      " - 110s - loss: 0.4970 - acc: 0.8208 - val_loss: 1.0177 - val_acc: 0.7324\n",
      "Epoch 66/4096\n",
      " - 110s - loss: 0.5236 - acc: 0.8184 - val_loss: 1.2322 - val_acc: 0.6816\n",
      "Epoch 67/4096\n",
      " - 111s - loss: 0.4952 - acc: 0.8159 - val_loss: 0.8442 - val_acc: 0.7578\n",
      "Epoch 68/4096\n",
      " - 111s - loss: 0.4819 - acc: 0.8342 - val_loss: 1.3345 - val_acc: 0.6377\n",
      "Epoch 69/4096\n",
      " - 111s - loss: 0.4780 - acc: 0.8281 - val_loss: 1.5718 - val_acc: 0.6123\n",
      "Epoch 70/4096\n",
      " - 110s - loss: 0.4661 - acc: 0.8313 - val_loss: 1.4147 - val_acc: 0.6064\n",
      "Epoch 71/4096\n",
      " - 114s - loss: 0.4606 - acc: 0.8325 - val_loss: 0.6496 - val_acc: 0.8252\n",
      "Epoch 72/4096\n",
      " - 111s - loss: 0.4786 - acc: 0.8311 - val_loss: 1.0054 - val_acc: 0.7051\n",
      "Epoch 73/4096\n",
      " - 114s - loss: 0.4518 - acc: 0.8394 - val_loss: 0.5859 - val_acc: 0.8320\n",
      "Epoch 74/4096\n",
      " - 113s - loss: 0.4767 - acc: 0.8274 - val_loss: 0.5728 - val_acc: 0.8174\n",
      "Epoch 75/4096\n",
      " - 111s - loss: 0.4657 - acc: 0.8386 - val_loss: 0.6734 - val_acc: 0.7617\n",
      "Epoch 76/4096\n",
      " - 111s - loss: 0.4539 - acc: 0.8420 - val_loss: 1.1094 - val_acc: 0.7441\n",
      "Epoch 77/4096\n",
      " - 110s - loss: 0.4507 - acc: 0.8347 - val_loss: 0.9422 - val_acc: 0.6924\n",
      "Epoch 78/4096\n",
      " - 111s - loss: 0.4632 - acc: 0.8372 - val_loss: 0.8232 - val_acc: 0.7764\n",
      "Epoch 79/4096\n",
      " - 110s - loss: 0.4347 - acc: 0.8464 - val_loss: 1.2887 - val_acc: 0.6934\n",
      "Epoch 80/4096\n",
      " - 110s - loss: 0.4253 - acc: 0.8486 - val_loss: 0.6059 - val_acc: 0.8311\n",
      "Epoch 81/4096\n",
      " - 110s - loss: 0.4286 - acc: 0.8472 - val_loss: 0.9930 - val_acc: 0.7480\n",
      "Epoch 82/4096\n",
      " - 110s - loss: 0.4499 - acc: 0.8406 - val_loss: 0.6339 - val_acc: 0.8193\n",
      "Epoch 83/4096\n",
      " - 111s - loss: 0.4413 - acc: 0.8445 - val_loss: 0.8157 - val_acc: 0.7578\n",
      "Epoch 84/4096\n",
      " - 110s - loss: 0.4488 - acc: 0.8433 - val_loss: 0.8585 - val_acc: 0.7285\n",
      "Epoch 85/4096\n",
      " - 110s - loss: 0.4561 - acc: 0.8359 - val_loss: 0.8133 - val_acc: 0.7207\n",
      "Epoch 86/4096\n",
      " - 112s - loss: 0.4062 - acc: 0.8569 - val_loss: 0.5570 - val_acc: 0.8018\n",
      "Epoch 87/4096\n",
      " - 111s - loss: 0.4181 - acc: 0.8433 - val_loss: 0.8306 - val_acc: 0.7510\n",
      "Epoch 88/4096\n",
      " - 111s - loss: 0.4194 - acc: 0.8521 - val_loss: 0.8893 - val_acc: 0.7705\n",
      "Epoch 89/4096\n",
      " - 111s - loss: 0.4356 - acc: 0.8535 - val_loss: 0.5636 - val_acc: 0.8096\n",
      "Epoch 90/4096\n",
      " - 111s - loss: 0.4150 - acc: 0.8506 - val_loss: 0.7587 - val_acc: 0.7490\n",
      "Epoch 91/4096\n",
      " - 111s - loss: 0.4476 - acc: 0.8440 - val_loss: 1.3261 - val_acc: 0.6816\n",
      "Epoch 92/4096\n",
      " - 110s - loss: 0.4206 - acc: 0.8511 - val_loss: 0.6752 - val_acc: 0.7969\n",
      "Epoch 93/4096\n",
      " - 110s - loss: 0.4061 - acc: 0.8538 - val_loss: 0.9060 - val_acc: 0.7334\n",
      "Epoch 94/4096\n",
      " - 111s - loss: 0.3915 - acc: 0.8628 - val_loss: 0.6999 - val_acc: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/4096\n",
      " - 111s - loss: 0.4228 - acc: 0.8469 - val_loss: 1.3391 - val_acc: 0.6299\n",
      "Epoch 96/4096\n",
      " - 110s - loss: 0.3943 - acc: 0.8550 - val_loss: 0.6739 - val_acc: 0.7979\n",
      "Epoch 97/4096\n",
      " - 110s - loss: 0.4013 - acc: 0.8623 - val_loss: 0.8569 - val_acc: 0.7393\n",
      "Epoch 98/4096\n",
      " - 110s - loss: 0.4271 - acc: 0.8518 - val_loss: 0.6675 - val_acc: 0.8252\n",
      "Epoch 99/4096\n",
      " - 110s - loss: 0.3888 - acc: 0.8645 - val_loss: 0.9236 - val_acc: 0.7334\n",
      "Epoch 100/4096\n",
      " - 110s - loss: 0.4119 - acc: 0.8511 - val_loss: 0.7992 - val_acc: 0.7949\n",
      "Epoch 101/4096\n",
      " - 110s - loss: 0.3913 - acc: 0.8613 - val_loss: 0.5782 - val_acc: 0.7939\n",
      "Epoch 102/4096\n",
      " - 110s - loss: 0.3972 - acc: 0.8584 - val_loss: 0.7060 - val_acc: 0.8047\n",
      "Epoch 103/4096\n",
      " - 111s - loss: 0.3836 - acc: 0.8596 - val_loss: 1.1568 - val_acc: 0.6562\n",
      "Epoch 104/4096\n",
      " - 110s - loss: 0.3734 - acc: 0.8643 - val_loss: 0.6565 - val_acc: 0.8184\n",
      "Epoch 105/4096\n",
      " - 112s - loss: 0.3576 - acc: 0.8738 - val_loss: 0.5552 - val_acc: 0.8271\n",
      "Epoch 106/4096\n",
      " - 111s - loss: 0.3739 - acc: 0.8684 - val_loss: 1.0000 - val_acc: 0.7588\n",
      "Epoch 107/4096\n",
      " - 111s - loss: 0.3755 - acc: 0.8650 - val_loss: 0.9643 - val_acc: 0.7803\n",
      "Epoch 108/4096\n",
      " - 111s - loss: 0.4096 - acc: 0.8530 - val_loss: 0.8691 - val_acc: 0.7246\n",
      "Epoch 109/4096\n",
      " - 110s - loss: 0.3898 - acc: 0.8557 - val_loss: 0.6690 - val_acc: 0.7852\n",
      "Epoch 110/4096\n",
      " - 111s - loss: 0.3731 - acc: 0.8638 - val_loss: 1.3225 - val_acc: 0.6660\n",
      "Epoch 111/4096\n",
      " - 110s - loss: 0.3760 - acc: 0.8655 - val_loss: 0.6643 - val_acc: 0.7988\n",
      "Epoch 112/4096\n",
      " - 110s - loss: 0.3615 - acc: 0.8762 - val_loss: 0.5984 - val_acc: 0.8184\n",
      "Epoch 113/4096\n",
      " - 111s - loss: 0.3772 - acc: 0.8647 - val_loss: 0.6752 - val_acc: 0.7686\n",
      "Epoch 114/4096\n",
      " - 113s - loss: 0.3812 - acc: 0.8665 - val_loss: 0.4092 - val_acc: 0.8525\n",
      "Epoch 115/4096\n",
      " - 111s - loss: 0.3606 - acc: 0.8728 - val_loss: 0.8717 - val_acc: 0.7920\n",
      "Epoch 116/4096\n",
      " - 120s - loss: 0.3753 - acc: 0.8711 - val_loss: 1.1172 - val_acc: 0.6719\n",
      "Epoch 117/4096\n",
      " - 128s - loss: 0.3329 - acc: 0.8804 - val_loss: 0.3223 - val_acc: 0.8965\n",
      "Epoch 118/4096\n",
      " - 126s - loss: 0.2736 - acc: 0.9038 - val_loss: 0.2759 - val_acc: 0.9014\n",
      "Epoch 119/4096\n",
      " - 128s - loss: 0.2521 - acc: 0.9102 - val_loss: 0.2478 - val_acc: 0.9160\n",
      "Epoch 120/4096\n",
      " - 127s - loss: 0.2774 - acc: 0.9045 - val_loss: 0.2285 - val_acc: 0.9180\n",
      "Epoch 121/4096\n",
      " - 123s - loss: 0.2452 - acc: 0.9119 - val_loss: 0.2340 - val_acc: 0.9180\n",
      "Epoch 122/4096\n",
      " - 127s - loss: 0.2546 - acc: 0.9106 - val_loss: 0.2118 - val_acc: 0.9258\n",
      "Epoch 123/4096\n",
      " - 128s - loss: 0.2501 - acc: 0.9070 - val_loss: 0.2110 - val_acc: 0.9268\n",
      "Epoch 124/4096\n",
      " - 123s - loss: 0.2367 - acc: 0.9121 - val_loss: 0.2327 - val_acc: 0.9199\n",
      "Epoch 125/4096\n",
      " - 124s - loss: 0.2516 - acc: 0.9104 - val_loss: 0.2269 - val_acc: 0.9268\n",
      "Epoch 126/4096\n",
      " - 124s - loss: 0.2500 - acc: 0.9111 - val_loss: 0.2310 - val_acc: 0.9385\n",
      "Epoch 127/4096\n",
      " - 128s - loss: 0.2506 - acc: 0.9133 - val_loss: 0.1878 - val_acc: 0.9463\n",
      "Epoch 128/4096\n",
      " - 124s - loss: 0.2386 - acc: 0.9167 - val_loss: 0.2581 - val_acc: 0.9121\n",
      "Epoch 129/4096\n",
      " - 122s - loss: 0.2287 - acc: 0.9121 - val_loss: 0.2476 - val_acc: 0.9160\n",
      "Epoch 130/4096\n",
      " - 124s - loss: 0.2518 - acc: 0.9080 - val_loss: 0.2398 - val_acc: 0.9258\n",
      "Epoch 131/4096\n",
      " - 124s - loss: 0.2353 - acc: 0.9170 - val_loss: 0.2276 - val_acc: 0.9199\n",
      "Epoch 132/4096\n",
      " - 122s - loss: 0.2236 - acc: 0.9124 - val_loss: 0.2057 - val_acc: 0.9346\n",
      "Epoch 133/4096\n",
      " - 127s - loss: 0.2164 - acc: 0.9158 - val_loss: 0.1581 - val_acc: 0.9492\n",
      "Epoch 134/4096\n",
      " - 125s - loss: 0.2193 - acc: 0.9233 - val_loss: 0.1888 - val_acc: 0.9355\n",
      "Epoch 135/4096\n",
      " - 124s - loss: 0.2296 - acc: 0.9155 - val_loss: 0.2001 - val_acc: 0.9404\n",
      "Epoch 136/4096\n",
      " - 124s - loss: 0.2235 - acc: 0.9185 - val_loss: 0.2095 - val_acc: 0.9277\n",
      "Epoch 137/4096\n",
      " - 123s - loss: 0.2176 - acc: 0.9229 - val_loss: 0.2020 - val_acc: 0.9277\n",
      "Epoch 138/4096\n",
      " - 124s - loss: 0.2089 - acc: 0.9263 - val_loss: 0.2347 - val_acc: 0.9229\n",
      "Epoch 139/4096\n",
      " - 126s - loss: 0.2028 - acc: 0.9268 - val_loss: 0.1616 - val_acc: 0.9531\n",
      "Epoch 140/4096\n",
      " - 124s - loss: 0.2128 - acc: 0.9231 - val_loss: 0.1801 - val_acc: 0.9375\n",
      "Epoch 141/4096\n",
      " - 124s - loss: 0.1932 - acc: 0.9287 - val_loss: 0.1591 - val_acc: 0.9521\n",
      "Epoch 142/4096\n",
      " - 124s - loss: 0.1918 - acc: 0.9260 - val_loss: 0.2023 - val_acc: 0.9395\n",
      "Epoch 143/4096\n",
      " - 124s - loss: 0.1934 - acc: 0.9285 - val_loss: 0.2130 - val_acc: 0.9365\n",
      "Epoch 144/4096\n",
      " - 126s - loss: 0.2164 - acc: 0.9211 - val_loss: 0.1550 - val_acc: 0.9473\n",
      "Epoch 145/4096\n",
      " - 124s - loss: 0.1896 - acc: 0.9285 - val_loss: 0.2085 - val_acc: 0.9326\n",
      "Epoch 146/4096\n",
      " - 123s - loss: 0.1950 - acc: 0.9304 - val_loss: 0.2055 - val_acc: 0.9326\n",
      "Epoch 147/4096\n",
      " - 123s - loss: 0.1876 - acc: 0.9312 - val_loss: 0.1747 - val_acc: 0.9453\n",
      "Epoch 148/4096\n",
      " - 124s - loss: 0.1867 - acc: 0.9309 - val_loss: 0.2402 - val_acc: 0.9229\n",
      "Epoch 149/4096\n",
      " - 123s - loss: 0.1919 - acc: 0.9314 - val_loss: 0.2252 - val_acc: 0.9248\n",
      "Epoch 150/4096\n",
      " - 123s - loss: 0.2185 - acc: 0.9146 - val_loss: 0.2377 - val_acc: 0.9277\n",
      "Epoch 151/4096\n",
      " - 124s - loss: 0.1943 - acc: 0.9304 - val_loss: 0.2501 - val_acc: 0.9336\n",
      "Epoch 152/4096\n",
      " - 124s - loss: 0.2036 - acc: 0.9260 - val_loss: 0.2484 - val_acc: 0.9219\n",
      "Epoch 153/4096\n",
      " - 123s - loss: 0.1982 - acc: 0.9270 - val_loss: 0.1872 - val_acc: 0.9395\n",
      "Epoch 154/4096\n",
      " - 124s - loss: 0.1942 - acc: 0.9287 - val_loss: 0.2321 - val_acc: 0.9434\n",
      "Epoch 155/4096\n",
      " - 125s - loss: 0.2040 - acc: 0.9211 - val_loss: 0.2093 - val_acc: 0.9385\n",
      "Epoch 156/4096\n",
      " - 124s - loss: 0.2007 - acc: 0.9280 - val_loss: 0.1714 - val_acc: 0.9443\n",
      "Epoch 157/4096\n",
      " - 124s - loss: 0.2095 - acc: 0.9211 - val_loss: 0.1819 - val_acc: 0.9434\n",
      "Epoch 158/4096\n",
      " - 124s - loss: 0.2040 - acc: 0.9233 - val_loss: 0.1631 - val_acc: 0.9424\n",
      "Epoch 159/4096\n",
      " - 125s - loss: 0.1941 - acc: 0.9270 - val_loss: 0.1443 - val_acc: 0.9463\n",
      "Epoch 160/4096\n",
      " - 124s - loss: 0.1858 - acc: 0.9302 - val_loss: 0.1494 - val_acc: 0.9512\n",
      "Epoch 161/4096\n",
      " - 124s - loss: 0.1927 - acc: 0.9270 - val_loss: 0.1627 - val_acc: 0.9463\n",
      "Epoch 162/4096\n",
      " - 123s - loss: 0.1884 - acc: 0.9270 - val_loss: 0.1729 - val_acc: 0.9404\n",
      "Epoch 163/4096\n",
      " - 124s - loss: 0.2021 - acc: 0.9243 - val_loss: 0.1839 - val_acc: 0.9316\n",
      "Epoch 164/4096\n",
      " - 123s - loss: 0.1710 - acc: 0.9343 - val_loss: 0.1563 - val_acc: 0.9473\n",
      "Epoch 165/4096\n",
      " - 122s - loss: 0.1760 - acc: 0.9333 - val_loss: 0.1816 - val_acc: 0.9395\n",
      "Epoch 166/4096\n",
      " - 123s - loss: 0.1860 - acc: 0.9316 - val_loss: 0.1939 - val_acc: 0.9414\n",
      "Epoch 167/4096\n",
      " - 124s - loss: 0.1923 - acc: 0.9299 - val_loss: 0.1802 - val_acc: 0.9316\n",
      "Epoch 168/4096\n",
      " - 124s - loss: 0.1768 - acc: 0.9331 - val_loss: 0.2003 - val_acc: 0.9463\n",
      "Epoch 169/4096\n",
      " - 125s - loss: 0.1945 - acc: 0.9241 - val_loss: 0.2048 - val_acc: 0.9404\n",
      "Epoch 170/4096\n",
      " - 124s - loss: 0.1940 - acc: 0.9290 - val_loss: 0.1973 - val_acc: 0.9365\n",
      "Epoch 171/4096\n",
      " - 123s - loss: 0.1943 - acc: 0.9299 - val_loss: 0.1706 - val_acc: 0.9375\n",
      "Epoch 172/4096\n",
      " - 124s - loss: 0.2106 - acc: 0.9253 - val_loss: 0.1779 - val_acc: 0.9453\n",
      "Epoch 173/4096\n",
      " - 123s - loss: 0.1970 - acc: 0.9268 - val_loss: 0.1773 - val_acc: 0.9414\n",
      "Epoch 174/4096\n",
      " - 123s - loss: 0.1897 - acc: 0.9255 - val_loss: 0.1652 - val_acc: 0.9414\n",
      "Epoch 175/4096\n",
      " - 124s - loss: 0.1790 - acc: 0.9348 - val_loss: 0.1524 - val_acc: 0.9443\n",
      "Epoch 176/4096\n",
      " - 126s - loss: 0.1772 - acc: 0.9351 - val_loss: 0.1514 - val_acc: 0.9551\n",
      "Epoch 177/4096\n",
      " - 124s - loss: 0.1842 - acc: 0.9309 - val_loss: 0.1454 - val_acc: 0.9473\n",
      "Epoch 178/4096\n",
      " - 124s - loss: 0.1785 - acc: 0.9287 - val_loss: 0.1967 - val_acc: 0.9414\n",
      "Epoch 179/4096\n",
      " - 125s - loss: 0.1800 - acc: 0.9294 - val_loss: 0.1788 - val_acc: 0.9355\n",
      "Epoch 180/4096\n",
      " - 124s - loss: 0.1880 - acc: 0.9275 - val_loss: 0.1516 - val_acc: 0.9463\n",
      "Epoch 181/4096\n",
      " - 123s - loss: 0.1722 - acc: 0.9346 - val_loss: 0.1583 - val_acc: 0.9453\n",
      "Epoch 182/4096\n",
      " - 124s - loss: 0.1924 - acc: 0.9268 - val_loss: 0.1776 - val_acc: 0.9336\n",
      "Epoch 183/4096\n",
      " - 123s - loss: 0.1681 - acc: 0.9402 - val_loss: 0.1746 - val_acc: 0.9355\n",
      "Epoch 184/4096\n",
      " - 123s - loss: 0.2099 - acc: 0.9221 - val_loss: 0.1858 - val_acc: 0.9385\n",
      "Epoch 185/4096\n",
      " - 124s - loss: 0.1864 - acc: 0.9294 - val_loss: 0.1748 - val_acc: 0.9473\n",
      "Epoch 186/4096\n",
      " - 126s - loss: 0.1757 - acc: 0.9314 - val_loss: 0.1286 - val_acc: 0.9619\n",
      "Epoch 187/4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 124s - loss: 0.1659 - acc: 0.9329 - val_loss: 0.1504 - val_acc: 0.9404\n",
      "Epoch 188/4096\n",
      " - 124s - loss: 0.1980 - acc: 0.9287 - val_loss: 0.1557 - val_acc: 0.9424\n",
      "Epoch 189/4096\n",
      " - 124s - loss: 0.1679 - acc: 0.9336 - val_loss: 0.1693 - val_acc: 0.9414\n",
      "Epoch 190/4096\n",
      " - 124s - loss: 0.1694 - acc: 0.9351 - val_loss: 0.1793 - val_acc: 0.9346\n",
      "Epoch 191/4096\n",
      " - 124s - loss: 0.1742 - acc: 0.9346 - val_loss: 0.1588 - val_acc: 0.9531\n",
      "Epoch 192/4096\n",
      " - 124s - loss: 0.1722 - acc: 0.9409 - val_loss: 0.1931 - val_acc: 0.9434\n",
      "Epoch 193/4096\n",
      " - 123s - loss: 0.1771 - acc: 0.9373 - val_loss: 0.1675 - val_acc: 0.9434\n",
      "Epoch 194/4096\n",
      " - 124s - loss: 0.1743 - acc: 0.9370 - val_loss: 0.1634 - val_acc: 0.9375\n",
      "Epoch 195/4096\n",
      " - 124s - loss: 0.1895 - acc: 0.9233 - val_loss: 0.1581 - val_acc: 0.9434\n",
      "Epoch 196/4096\n",
      " - 124s - loss: 0.1894 - acc: 0.9343 - val_loss: 0.1614 - val_acc: 0.9561\n",
      "Epoch 197/4096\n",
      " - 124s - loss: 0.2059 - acc: 0.9209 - val_loss: 0.1789 - val_acc: 0.9385\n",
      "Epoch 198/4096\n",
      " - 123s - loss: 0.1706 - acc: 0.9370 - val_loss: 0.1459 - val_acc: 0.9502\n",
      "Epoch 199/4096\n",
      " - 123s - loss: 0.1788 - acc: 0.9336 - val_loss: 0.1600 - val_acc: 0.9395\n",
      "Epoch 200/4096\n",
      " - 124s - loss: 0.1673 - acc: 0.9358 - val_loss: 0.1902 - val_acc: 0.9414\n",
      "Epoch 201/4096\n",
      " - 122s - loss: 0.1749 - acc: 0.9343 - val_loss: 0.1501 - val_acc: 0.9541\n",
      "Epoch 202/4096\n",
      " - 124s - loss: 0.1850 - acc: 0.9341 - val_loss: 0.1538 - val_acc: 0.9482\n",
      "Epoch 203/4096\n",
      " - 124s - loss: 0.1802 - acc: 0.9360 - val_loss: 0.1829 - val_acc: 0.9385\n",
      "Epoch 204/4096\n",
      " - 123s - loss: 0.1961 - acc: 0.9265 - val_loss: 0.1691 - val_acc: 0.9473\n",
      "Epoch 205/4096\n",
      " - 124s - loss: 0.1756 - acc: 0.9309 - val_loss: 0.1766 - val_acc: 0.9414\n",
      "Epoch 206/4096\n",
      " - 126s - loss: 0.1797 - acc: 0.9299 - val_loss: 0.1529 - val_acc: 0.9473\n",
      "Epoch 207/4096\n",
      " - 123s - loss: 0.1876 - acc: 0.9294 - val_loss: 0.2018 - val_acc: 0.9482\n",
      "Epoch 208/4096\n",
      " - 124s - loss: 0.1901 - acc: 0.9312 - val_loss: 0.1861 - val_acc: 0.9395\n",
      "Epoch 209/4096\n",
      " - 124s - loss: 0.1830 - acc: 0.9316 - val_loss: 0.1806 - val_acc: 0.9375\n",
      "Epoch 210/4096\n",
      " - 123s - loss: 0.2036 - acc: 0.9221 - val_loss: 0.1732 - val_acc: 0.9385\n",
      "Epoch 211/4096\n",
      " - 123s - loss: 0.1734 - acc: 0.9353 - val_loss: 0.1803 - val_acc: 0.9365\n",
      "Epoch 212/4096\n",
      " - 124s - loss: 0.2021 - acc: 0.9243 - val_loss: 0.1570 - val_acc: 0.9551\n",
      "Epoch 213/4096\n",
      " - 123s - loss: 0.1946 - acc: 0.9263 - val_loss: 0.1531 - val_acc: 0.9502\n",
      "Epoch 214/4096\n",
      " - 124s - loss: 0.1744 - acc: 0.9341 - val_loss: 0.1727 - val_acc: 0.9395\n",
      "Epoch 215/4096\n",
      " - 124s - loss: 0.1853 - acc: 0.9275 - val_loss: 0.1925 - val_acc: 0.9375\n",
      "Epoch 216/4096\n",
      " - 124s - loss: 0.1794 - acc: 0.9373 - val_loss: 0.1966 - val_acc: 0.9355\n",
      "Epoch 217/4096\n",
      " - 124s - loss: 0.1899 - acc: 0.9258 - val_loss: 0.1430 - val_acc: 0.9492\n",
      "Epoch 218/4096\n",
      " - 123s - loss: 0.1787 - acc: 0.9331 - val_loss: 0.1432 - val_acc: 0.9531\n",
      "Epoch 219/4096\n",
      " - 124s - loss: 0.1795 - acc: 0.9319 - val_loss: 0.1767 - val_acc: 0.9404\n",
      "Epoch 220/4096\n",
      " - 124s - loss: 0.1755 - acc: 0.9333 - val_loss: 0.1778 - val_acc: 0.9385\n",
      "Epoch 221/4096\n",
      " - 125s - loss: 0.1750 - acc: 0.9343 - val_loss: 0.1557 - val_acc: 0.9492\n",
      "Epoch 222/4096\n",
      " - 124s - loss: 0.1943 - acc: 0.9265 - val_loss: 0.1641 - val_acc: 0.9414\n",
      "Epoch 223/4096\n",
      " - 123s - loss: 0.1937 - acc: 0.9299 - val_loss: 0.1590 - val_acc: 0.9443\n",
      "Epoch 224/4096\n",
      " - 124s - loss: 0.1938 - acc: 0.9243 - val_loss: 0.1291 - val_acc: 0.9512\n",
      "Epoch 225/4096\n",
      " - 124s - loss: 0.1829 - acc: 0.9280 - val_loss: 0.1817 - val_acc: 0.9385\n",
      "Epoch 226/4096\n",
      " - 125s - loss: 0.1750 - acc: 0.9316 - val_loss: 0.1505 - val_acc: 0.9512\n",
      "Epoch 227/4096\n",
      " - 123s - loss: 0.1888 - acc: 0.9275 - val_loss: 0.1704 - val_acc: 0.9443\n",
      "Epoch 228/4096\n",
      " - 125s - loss: 0.1752 - acc: 0.9351 - val_loss: 0.1366 - val_acc: 0.9531\n",
      "Epoch 229/4096\n",
      " - 126s - loss: 0.1770 - acc: 0.9353 - val_loss: 0.1245 - val_acc: 0.9463\n",
      "Epoch 230/4096\n",
      " - 124s - loss: 0.1776 - acc: 0.9351 - val_loss: 0.2098 - val_acc: 0.9316\n",
      "Epoch 231/4096\n",
      " - 123s - loss: 0.1756 - acc: 0.9338 - val_loss: 0.1725 - val_acc: 0.9443\n",
      "Epoch 232/4096\n",
      " - 123s - loss: 0.1845 - acc: 0.9297 - val_loss: 0.1784 - val_acc: 0.9414\n",
      "Epoch 233/4096\n",
      " - 124s - loss: 0.1880 - acc: 0.9260 - val_loss: 0.1477 - val_acc: 0.9512\n",
      "Epoch 234/4096\n",
      " - 124s - loss: 0.1842 - acc: 0.9287 - val_loss: 0.1683 - val_acc: 0.9414\n",
      "Epoch 235/4096\n",
      " - 123s - loss: 0.2048 - acc: 0.9253 - val_loss: 0.1933 - val_acc: 0.9336\n",
      "Epoch 236/4096\n",
      " - 124s - loss: 0.1629 - acc: 0.9355 - val_loss: 0.1902 - val_acc: 0.9424\n",
      "Epoch 237/4096\n",
      " - 125s - loss: 0.1910 - acc: 0.9299 - val_loss: 0.1210 - val_acc: 0.9541\n",
      "Epoch 238/4096\n",
      " - 123s - loss: 0.1769 - acc: 0.9263 - val_loss: 0.1469 - val_acc: 0.9473\n",
      "Epoch 239/4096\n",
      " - 123s - loss: 0.1937 - acc: 0.9229 - val_loss: 0.1807 - val_acc: 0.9326\n",
      "Epoch 240/4096\n",
      " - 123s - loss: 0.1849 - acc: 0.9290 - val_loss: 0.1570 - val_acc: 0.9541\n",
      "Epoch 241/4096\n",
      " - 124s - loss: 0.1895 - acc: 0.9265 - val_loss: 0.1420 - val_acc: 0.9502\n",
      "Epoch 242/4096\n",
      " - 124s - loss: 0.1828 - acc: 0.9285 - val_loss: 0.1783 - val_acc: 0.9365\n",
      "Epoch 243/4096\n",
      " - 123s - loss: 0.1833 - acc: 0.9290 - val_loss: 0.1610 - val_acc: 0.9492\n",
      "Epoch 244/4096\n",
      " - 124s - loss: 0.1881 - acc: 0.9270 - val_loss: 0.1266 - val_acc: 0.9512\n",
      "Epoch 245/4096\n",
      " - 123s - loss: 0.1886 - acc: 0.9285 - val_loss: 0.1833 - val_acc: 0.9307\n",
      "Epoch 246/4096\n",
      " - 122s - loss: 0.1716 - acc: 0.9385 - val_loss: 0.1709 - val_acc: 0.9365\n",
      "Epoch 247/4096\n",
      " - 123s - loss: 0.1705 - acc: 0.9377 - val_loss: 0.1858 - val_acc: 0.9375\n",
      "Epoch 248/4096\n",
      " - 124s - loss: 0.1739 - acc: 0.9343 - val_loss: 0.1609 - val_acc: 0.9443\n",
      "Epoch 249/4096\n",
      " - 122s - loss: 0.1784 - acc: 0.9316 - val_loss: 0.1931 - val_acc: 0.9346\n",
      "Epoch 250/4096\n",
      " - 123s - loss: 0.1777 - acc: 0.9326 - val_loss: 0.1446 - val_acc: 0.9434\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint('ieee-camera-'+session_name+'_acc.hdf5',\n",
    "                                   monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "model_checkpoint2 = ModelCheckpoint('ieee-camera-'+session_name+'_loss.hdf5',\n",
    "                                    monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "model_reducelr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10)\n",
    "model_earlystop = EarlyStopping(patience=64, monitor='val_acc')\n",
    "model.compile(optimizer=Adam(amsgrad=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "batch_size = 8*gdev_count\n",
    "train_history = model.fit_generator(gen(flickr_imgs+train_imgs, flickr_labels+train_labels, batch_size),\n",
    "                                    steps_per_epoch=math.ceil(4096/batch_size), epochs=2**12,\n",
    "                                    validation_data=gen(val_imgs, val_labels, batch_size),\n",
    "                                    validation_steps=math.ceil(1024/batch_size),\n",
    "                                    verbose=2, callbacks=[model_checkpoint, model_earlystop, model_checkpoint2, model_reducelr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - 54s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0002a04_manip.tif</td>\n",
       "      <td>LG-Nexus-5x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_001e31c_unalt.tif</td>\n",
       "      <td>iPhone-4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00275cf_manip.tif</td>\n",
       "      <td>iPhone-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0034113_unalt.tif</td>\n",
       "      <td>Samsung-Galaxy-S4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00344b7_unalt.tif</td>\n",
       "      <td>Motorola-X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fname             camera\n",
       "0  img_0002a04_manip.tif        LG-Nexus-5x\n",
       "1  img_001e31c_unalt.tif          iPhone-4s\n",
       "2  img_00275cf_manip.tif           iPhone-6\n",
       "3  img_0034113_unalt.tif  Samsung-Galaxy-S4\n",
       "4  img_00344b7_unalt.tif         Motorola-X"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc ver.\n",
    "model.load_weights('ieee-camera-'+session_name+'_acc.hdf5')\n",
    "predicted = model.predict(np.asarray(test_imgs), batch_size=32*gdev_count, verbose=1)\n",
    "label_list = []\n",
    "for p in predicted:\n",
    "    label_list.append(cameras[p.argsort()[::-1][0]])\n",
    "submit_df = pd.concat([test,pd.DataFrame({'camera':label_list})],axis=1)\n",
    "submit_df.to_csv(session_name+'_acc.csv', index=False)\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2640/2640 [==============================] - 37s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_0002a04_manip.tif</td>\n",
       "      <td>LG-Nexus-5x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_001e31c_unalt.tif</td>\n",
       "      <td>iPhone-4s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00275cf_manip.tif</td>\n",
       "      <td>iPhone-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_0034113_unalt.tif</td>\n",
       "      <td>Samsung-Galaxy-S4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00344b7_unalt.tif</td>\n",
       "      <td>Motorola-X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fname             camera\n",
       "0  img_0002a04_manip.tif        LG-Nexus-5x\n",
       "1  img_001e31c_unalt.tif          iPhone-4s\n",
       "2  img_00275cf_manip.tif           iPhone-6\n",
       "3  img_0034113_unalt.tif  Samsung-Galaxy-S4\n",
       "4  img_00344b7_unalt.tif         Motorola-X"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss ver.\n",
    "model.load_weights('ieee-camera-'+session_name+'_loss.hdf5')\n",
    "predicted = model.predict(np.asarray(test_imgs), batch_size=32*gdev_count, verbose=1)\n",
    "label_list = []\n",
    "for p in predicted:\n",
    "    label_list.append(cameras[p.argsort()[::-1][0]])\n",
    "submit_df = pd.concat([test,pd.DataFrame({'camera':label_list})],axis=1)\n",
    "submit_df.to_csv(session_name+'_loss.csv', index=False)\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown Notebook Kernel on Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.delete();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
